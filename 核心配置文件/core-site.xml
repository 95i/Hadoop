<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
 <!-- 默认文件系统的名称。通过URI中schema区分不同文件系统。-->
	 <!-- file:///本地文件系统 hdfs:// hadoop分布式文件系统 gfs://。-->
	 <!-- hdfs文件系统访问地址：http://主角色地址:8020。-->
    <!--现在我们把主角色设为HadoopVM1主机  那么这里应该填上主角是的地址Hadoopvm1或者192.168.126.11-->
	<!-- 设置默认使用的文件系统 Hadoop 支持 file 、 HDFS 、 GFS 、 ali|Amazon 云等文件系统 -->
    <property>
            <name>fs.defaultFS</name>
            <value>hdfs://Hadoopvm1:8020</value>
    </property>
    <!-- 设置 Hadoop 本地保存数据路径 -->
    <property>
            <name>hadoop.tmp.dir</name>
            <value>/Hadoop/export/data/hadoop-3.1.3</value>
    </property>
    <!-- 设置 HDFS web UI 用户身份 -->
    <property>
            <name>hadoop.http.staticuser.user</name>
            <value>root</value>
    </property>
          <!-- 整合 hive  用户代理设置 -->
    <property>
            <name>hadoop.proxyuser.root.hosts</name>
            <value>*</value>
    </property>
    <property>
            <name>hadoop.proxyuser.root.groups</name>
            <value>*</value>
    </property>
    <!-- 垃圾桶文件保存时间 -->
    <property>
            <name>fs.trash.interval</name>
            <value>1440</value>
    </property>
</configuration>
